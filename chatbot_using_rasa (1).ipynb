{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below makes sure that you get some information which you can use for debugging, cleans up the output from unecessary warnings and defines a function which whill print json outputs in a nicely formatted way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python pip install -U rasa_nlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import sklearn\n",
    "import spacy\n",
    "import rasa_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example : Conversation_1:\n",
    "U: Hello.\n",
    "B: Hey! I am ThingWorx assistant. How can I help?\n",
    "U: what are the machines available\n",
    "B: Forklift001,Forklift002,Forklift003,Forklift004,Forklift005,Forklift006\n",
    "U: show me about forklift001\n",
    "B: to see the status click here : http://www.iotspace.io/Thingworx/Things/Forklift001/Properties\n",
    "U: Thanks.\n",
    "B: Happy reading.\n",
    "U: Goodbye.\n",
    "B: Goodbye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the training data for language understanding model\n",
    "Lets create some training data here by grouping user messages by their intents. The intent describes what the messages mean. Another important part of training data are entities - pieces of information which help a chatbot understand what specifically a user is asking about. Entities are labeled using the markdown link syntex: [entity value](entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "- nope\n",
    "- definitely no\n",
    "- no no\n",
    "\n",
    "\n",
    "## intent:machine_status\n",
    "- what are the machines available\n",
    "- list the machines\n",
    "\n",
    "## intent:machine_name\n",
    "- show me about [forklift001](machine_type)\n",
    "- [forklift002](machine_type)\n",
    "- about [forklift002](machine_type)\n",
    "- maybe [forklift003](machine_type)\n",
    "- about [forklift004](machine_type)\n",
    "- for [forklift005](machine_type)\n",
    "- about [forklift006](machine_type)\n",
    "- maybe about [forklift001](machine_type)\n",
    "\n",
    "## intent:machine_status+machine_name\n",
    "- show me the machine status of [forklift002](machine_type)\n",
    "- give me the details of [forklift003](machine_type)\n",
    "\n",
    "\n",
    "## intent:thanks\n",
    "- thanks\n",
    "- thank you\n",
    "- thank you very much\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "- thank you loads\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "now we are going to create our nlu model. We can do that by constructing the processing pipeline which defines how structured data is extracted from unstructured user inputs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we are not using any sepcific nlp or nlu packages as our project dosent need those if you want you can use it but it will make your bot more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"                              #defines how unstructured sentences will be tokenized\n",
    "- name: \"ner_crf\"                                           #defines the model which will be used for entity extraction\n",
    "- name: \"intent_featurizer_count_vectors\"                   #creates sentence representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"            #defines a classifier for intent classification\n",
    "  intent_tokenization_flag: true                            #sets the flag for intent label tokenization\n",
    "  intent_split_symbol: \"+\"                                  #defines the character on which intent labels should be tokenized\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Rasa NLU Model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We're going to train a model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a \"greet\" intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 51 (7 distinct intents)\n",
      "\t- Found intents: 'machine_name', 'machine_status', 'machine_status+machine_name', 'goodbye', 'deny', 'greet', 'thanks'\n",
      "\t- entity examples: 10 (1 distinct entities)\n",
      "\t- found entities: 'machine_type'\n",
      "\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `tokenizer_whitespace`, you should change it to its class name: `WhitespaceTokenizer`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `ner_crf`, you should change it to its class name: `CRFEntityExtractor`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `intent_featurizer_count_vectors`, you should change it to its class name: `CountVectorsFeaturizer`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `intent_classifier_tensorflow_embedding`, you should change it to its class name: `EmbeddingIntentClassifier`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `tokenizer_whitespace`, you should change it to its class name: `WhitespaceTokenizer`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `tokenizer_whitespace`, you should change it to its class name: `WhitespaceTokenizer`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `ner_crf`, you should change it to its class name: `CRFEntityExtractor`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `ner_crf`, you should change it to its class name: `CRFEntityExtractor`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `intent_featurizer_count_vectors`, you should change it to its class name: `CountVectorsFeaturizer`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `intent_featurizer_count_vectors`, you should change it to its class name: `CountVectorsFeaturizer`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `intent_classifier_tensorflow_embedding`, you should change it to its class name: `EmbeddingIntentClassifier`.\n",
      "WARNING:rasa_nlu.registry:DEPRECATION warning: your nlu config file contains old style component name `intent_classifier_tensorflow_embedding`, you should change it to its class name: `EmbeddingIntentClassifier`.\n",
      "INFO:rasa_nlu.model:Starting to train component WhitespaceTokenizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component CRFEntityExtractor\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component CountVectorsFeaturizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component EmbeddingIntentClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\rasa_nlu\\classifiers\\embedding_intent_classifier.py:285: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\rasa_nlu\\classifiers\\embedding_intent_classifier.py:286: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:rasa_nlu.classifiers.embedding_intent_classifier:Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|████████████████████████████████████████████████| 300/300 [00:02<00:00, 136.95it/s, loss=0.105, acc=0.980]\n",
      "INFO:rasa_nlu.classifiers.embedding_intent_classifier:Finished training embedding classifier, loss=0.105, train accuracy=0.980\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'C:\\Users\\sreeram\\Desktop\\chatbot\\models\\nlu\\default\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data, verbose=True)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Stories\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The training data for dialogue management models is called stories. A story is an actual conversation where user inputs are expressed as intents as well as corresponding entities, and chatbot responses are expressed as actions.\n",
    "\n",
    "Let's take a look into the format of the stories in more detail:\n",
    "\n",
    "A story starts with ## and you can give it a name. Lines that start with * are messages sent by the user. Although you don't write the actual message, but rather the intent (and the entities) that represent what the user means. Lines that start with - are actions taken by your bot. In this case all of our actions are just messages sent back to the user, like utter_greet, but in general an action can do anything, including calling an API and interacting with the outside world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories_md' (str) to file 'stories.md'.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "stories_md = \"\"\"\n",
    "\n",
    "\n",
    "## Suggestion path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* machine_status\n",
    "  - utter_list\n",
    "* machine_name{\"machine_type\":\"forklift001\"}\n",
    "  - action_machine_link\n",
    "  - utter_link\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## Suggestion path 2\n",
    "* greet\n",
    "  - utter_greet\n",
    "* machine_status+machine_name{\"machine_type\":\"forklift001\"}\n",
    "  - action_machine_link\n",
    "  - utter_link\n",
    "* thanks\n",
    "  - utter_welcome\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## Suggestion path 3\n",
    "* greet\n",
    "  - utter_greet\n",
    "* machine_name{\"machine_type\":\"forklift001\"}\n",
    "  - action_machine_link\n",
    "  - utter_link\n",
    "* deny\n",
    "  - utter_goodbye\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Domain is the place where we define all our intents entities and the templates for the answers an assistant should use to respond to the user and slots which will help the assistant to keep track of the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain_yml' (str) to file 'domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- thanks\n",
    "- deny\n",
    "- machine_status+machine_name\n",
    "- machine_status\n",
    "- machine_name\n",
    "slots:\n",
    "  machine_type:\n",
    "    type: text\n",
    "    \n",
    "entities:\n",
    "- paper_type\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_goodbye\n",
    "- utter_link\n",
    "- utter_welcome\n",
    "- utter_list\n",
    "- action_machine_link\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! I am ThingWorx assistant. How can I help\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Have a great day!\"\n",
    "\n",
    "  utter_link:\n",
    "  - text: \"to see the status click here : {machine_type}\"\n",
    "  \n",
    "  utter_welcome:\n",
    "  - text: \"It was pleasure serving you\"\n",
    "  \n",
    "  utter_list:\n",
    "  - text: \"Forklift001,Forklift002,Forklift003,Forklift004,Forklift005,Forklift006\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The responses of the assistant can be more than just simple text responses-we can create links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'custom_action' (str) to file 'actions.py'.\n"
     ]
    }
   ],
   "source": [
    "custom_action = \"\"\"\n",
    "\n",
    "from rasa_sdk import Action\n",
    "from rasa_sdk.events import SlotSet\n",
    "\n",
    "import requests\n",
    "\n",
    "class action_machine_link(Action):\n",
    "    def name(self):\n",
    "        return \"action_machine_link\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "\n",
    "        machine_type = tracker.get_slot('machine_type')\n",
    "        link=\"\"\n",
    "        if('f' in machine_type):\n",
    "            machine_type=list(machine_type)\n",
    "            machine_type[0]='F'\n",
    "            machine_type=\"\".join(machine_type)\n",
    "            link=\"http://www.iotspace.io/Thingworx/Things/{}/Properties?apikey=e82d0e47-9f2a-42c6-b6e4-a9006cdf9b18\".format(machine_type)\n",
    "        else:\n",
    "             dispatcher.utter_message(\"wrong machine_type\")\n",
    "        dispatcher.utter_message(machine_type)\n",
    "        return [SlotSet(\"machine_type\",link)]\n",
    "        \n",
    "\"\"\"\n",
    "%store custom_action > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training your Dialogue Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to train the dialogue management model. We can specify what policies should be used to train it - in this case, the model is a neural network implemented in Keras which learns to predict which action to take next. We can also change the parameters of what percentage of training examples should be used for validation and how many epochs should be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:apscheduler.scheduler:Scheduler started\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 553.24it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 262.99it/s, # trackers=3]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 183.27it/s, # trackers=3]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 208.57it/s, # trackers=3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 23)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                7168      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 14)                462       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 7,630\n",
      "Trainable params: 7,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Fitting model with 48 total samples and a validation split of 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.6008 - acc: 0.093 - 1s 13ms/sample - loss: 2.6017 - acc: 0.0625\n",
      "Epoch 2/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.5536 - acc: 0.156 - 0s 320us/sample - loss: 2.5478 - acc: 0.1667\n",
      "Epoch 3/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.5120 - acc: 0.312 - 0s 414us/sample - loss: 2.5121 - acc: 0.3125\n",
      "Epoch 4/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.4904 - acc: 0.312 - 0s 362us/sample - loss: 2.4943 - acc: 0.2917\n",
      "Epoch 5/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.4782 - acc: 0.281 - 0s 382us/sample - loss: 2.4686 - acc: 0.2917\n",
      "Epoch 6/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.4491 - acc: 0.281 - 0s 382us/sample - loss: 2.4323 - acc: 0.3125\n",
      "Epoch 7/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.4054 - acc: 0.375 - 0s 393us/sample - loss: 2.4013 - acc: 0.4375\n",
      "Epoch 8/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.3721 - acc: 0.343 - 0s 341us/sample - loss: 2.3553 - acc: 0.3750\n",
      "Epoch 9/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.3412 - acc: 0.343 - 0s 424us/sample - loss: 2.3378 - acc: 0.3542\n",
      "Epoch 10/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.2959 - acc: 0.312 - 0s 310us/sample - loss: 2.3001 - acc: 0.3542\n",
      "Epoch 11/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.3143 - acc: 0.343 - 0s 362us/sample - loss: 2.2873 - acc: 0.3750\n",
      "Epoch 12/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.2762 - acc: 0.343 - 0s 382us/sample - loss: 2.2539 - acc: 0.3750\n",
      "Epoch 13/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.2502 - acc: 0.343 - 0s 351us/sample - loss: 2.2246 - acc: 0.3750\n",
      "Epoch 14/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.1968 - acc: 0.343 - 0s 372us/sample - loss: 2.1545 - acc: 0.3750\n",
      "Epoch 15/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.1288 - acc: 0.343 - 0s 347us/sample - loss: 2.1096 - acc: 0.3750\n",
      "Epoch 16/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.1298 - acc: 0.343 - 0s 300us/sample - loss: 2.0799 - acc: 0.3750\n",
      "Epoch 17/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.0896 - acc: 0.343 - 0s 300us/sample - loss: 2.0462 - acc: 0.3750\n",
      "Epoch 18/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.0580 - acc: 0.343 - 0s 341us/sample - loss: 2.0149 - acc: 0.3750\n",
      "Epoch 19/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.0335 - acc: 0.343 - 0s 399us/sample - loss: 1.9960 - acc: 0.3750\n",
      "Epoch 20/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.0527 - acc: 0.343 - 0s 362us/sample - loss: 1.9968 - acc: 0.3750\n",
      "Epoch 21/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.0276 - acc: 0.343 - 0s 289us/sample - loss: 1.9708 - acc: 0.3750\n",
      "Epoch 22/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.9491 - acc: 0.343 - 0s 372us/sample - loss: 1.9214 - acc: 0.3750\n",
      "Epoch 23/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.9738 - acc: 0.343 - 0s 362us/sample - loss: 1.9086 - acc: 0.3750\n",
      "Epoch 24/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.9680 - acc: 0.343 - 0s 341us/sample - loss: 1.9029 - acc: 0.3750\n",
      "Epoch 25/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.9102 - acc: 0.343 - 0s 403us/sample - loss: 1.8593 - acc: 0.3750\n",
      "Epoch 26/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8829 - acc: 0.343 - 0s 320us/sample - loss: 1.8116 - acc: 0.3750\n",
      "Epoch 27/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8834 - acc: 0.343 - 0s 279us/sample - loss: 1.8155 - acc: 0.3750\n",
      "Epoch 28/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8948 - acc: 0.343 - 0s 320us/sample - loss: 1.8263 - acc: 0.3750\n",
      "Epoch 29/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.9022 - acc: 0.343 - 0s 382us/sample - loss: 1.8169 - acc: 0.3750\n",
      "Epoch 30/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8555 - acc: 0.343 - 0s 300us/sample - loss: 1.7848 - acc: 0.3750\n",
      "Epoch 31/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8724 - acc: 0.343 - 0s 320us/sample - loss: 1.7766 - acc: 0.3750\n",
      "Epoch 32/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8306 - acc: 0.343 - 0s 362us/sample - loss: 1.7854 - acc: 0.3750\n",
      "Epoch 33/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8375 - acc: 0.343 - 0s 413us/sample - loss: 1.7486 - acc: 0.3750\n",
      "Epoch 34/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8166 - acc: 0.343 - 0s 238us/sample - loss: 1.7391 - acc: 0.3750\n",
      "Epoch 35/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8181 - acc: 0.343 - 0s 341us/sample - loss: 1.7235 - acc: 0.3750\n",
      "Epoch 36/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8134 - acc: 0.343 - 0s 362us/sample - loss: 1.7104 - acc: 0.3750\n",
      "Epoch 37/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7622 - acc: 0.343 - 0s 341us/sample - loss: 1.6841 - acc: 0.3750\n",
      "Epoch 38/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.8165 - acc: 0.343 - 0s 279us/sample - loss: 1.7082 - acc: 0.3750\n",
      "Epoch 39/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7869 - acc: 0.343 - 0s 382us/sample - loss: 1.6901 - acc: 0.3750\n",
      "Epoch 40/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7540 - acc: 0.343 - 0s 289us/sample - loss: 1.6625 - acc: 0.3750\n",
      "Epoch 41/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7900 - acc: 0.343 - 0s 300us/sample - loss: 1.6876 - acc: 0.3750\n",
      "Epoch 42/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7316 - acc: 0.343 - 0s 258us/sample - loss: 1.6401 - acc: 0.3750\n",
      "Epoch 43/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7458 - acc: 0.343 - 0s 372us/sample - loss: 1.6648 - acc: 0.3750\n",
      "Epoch 44/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7198 - acc: 0.343 - 0s 248us/sample - loss: 1.6104 - acc: 0.3750\n",
      "Epoch 45/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7325 - acc: 0.343 - 0s 372us/sample - loss: 1.6250 - acc: 0.3750\n",
      "Epoch 46/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7374 - acc: 0.343 - 0s 269us/sample - loss: 1.6207 - acc: 0.3750\n",
      "Epoch 47/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7326 - acc: 0.343 - 0s 248us/sample - loss: 1.6294 - acc: 0.3958\n",
      "Epoch 48/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6792 - acc: 0.343 - 0s 341us/sample - loss: 1.5802 - acc: 0.3750\n",
      "Epoch 49/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7060 - acc: 0.343 - 0s 279us/sample - loss: 1.5972 - acc: 0.3958\n",
      "Epoch 50/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6781 - acc: 0.343 - 0s 362us/sample - loss: 1.5803 - acc: 0.3750\n",
      "Epoch 51/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6623 - acc: 0.343 - 0s 300us/sample - loss: 1.5643 - acc: 0.3750\n",
      "Epoch 52/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6557 - acc: 0.343 - 0s 279us/sample - loss: 1.5371 - acc: 0.3958\n",
      "Epoch 53/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6198 - acc: 0.343 - 0s 279us/sample - loss: 1.5074 - acc: 0.3750\n",
      "Epoch 54/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6313 - acc: 0.375 - 0s 289us/sample - loss: 1.5241 - acc: 0.4375\n",
      "Epoch 55/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.343 - 0s 238us/sample - loss: 1.5034 - acc: 0.3750\n",
      "Epoch 56/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6290 - acc: 0.375 - 0s 300us/sample - loss: 1.5338 - acc: 0.3958\n",
      "Epoch 57/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5978 - acc: 0.375 - 0s 310us/sample - loss: 1.4856 - acc: 0.4375\n",
      "Epoch 58/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5726 - acc: 0.343 - 0s 279us/sample - loss: 1.4506 - acc: 0.4375\n",
      "Epoch 59/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.6046 - acc: 0.343 - 0s 269us/sample - loss: 1.4831 - acc: 0.4167\n",
      "Epoch 60/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5383 - acc: 0.406 - 0s 300us/sample - loss: 1.4385 - acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5383 - acc: 0.375 - 0s 279us/sample - loss: 1.4421 - acc: 0.4375\n",
      "Epoch 62/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5191 - acc: 0.406 - 0s 320us/sample - loss: 1.4094 - acc: 0.4792\n",
      "Epoch 63/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4993 - acc: 0.375 - 0s 310us/sample - loss: 1.3941 - acc: 0.4583\n",
      "Epoch 64/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4908 - acc: 0.406 - 0s 300us/sample - loss: 1.3700 - acc: 0.4792\n",
      "Epoch 65/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5547 - acc: 0.406 - 0s 289us/sample - loss: 1.4192 - acc: 0.4792\n",
      "Epoch 66/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4551 - acc: 0.468 - 0s 310us/sample - loss: 1.3451 - acc: 0.5208\n",
      "Epoch 67/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4713 - acc: 0.437 - 0s 331us/sample - loss: 1.3423 - acc: 0.5208\n",
      "Epoch 68/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4514 - acc: 0.406 - 0s 310us/sample - loss: 1.3248 - acc: 0.5000\n",
      "Epoch 69/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4332 - acc: 0.468 - 0s 289us/sample - loss: 1.3161 - acc: 0.5417\n",
      "Epoch 70/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4411 - acc: 0.468 - 0s 289us/sample - loss: 1.3166 - acc: 0.5417\n",
      "Epoch 71/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3994 - acc: 0.468 - 0s 310us/sample - loss: 1.2937 - acc: 0.5208\n",
      "Epoch 72/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4212 - acc: 0.500 - 0s 320us/sample - loss: 1.3318 - acc: 0.5417\n",
      "Epoch 73/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3683 - acc: 0.468 - 0s 362us/sample - loss: 1.2597 - acc: 0.5208\n",
      "Epoch 74/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3832 - acc: 0.500 - 0s 362us/sample - loss: 1.2692 - acc: 0.5625\n",
      "Epoch 75/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3928 - acc: 0.375 - 0s 289us/sample - loss: 1.2936 - acc: 0.4583\n",
      "Epoch 76/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.4146 - acc: 0.375 - 0s 289us/sample - loss: 1.2809 - acc: 0.4792\n",
      "Epoch 77/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3085 - acc: 0.500 - 0s 273us/sample - loss: 1.2043 - acc: 0.5625\n",
      "Epoch 78/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3393 - acc: 0.531 - 0s 331us/sample - loss: 1.2115 - acc: 0.5833\n",
      "Epoch 79/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3171 - acc: 0.531 - 0s 351us/sample - loss: 1.2038 - acc: 0.5833\n",
      "Epoch 80/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2663 - acc: 0.562 - 0s 279us/sample - loss: 1.1714 - acc: 0.5833\n",
      "Epoch 81/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2962 - acc: 0.531 - 0s 269us/sample - loss: 1.1943 - acc: 0.5833\n",
      "Epoch 82/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2956 - acc: 0.531 - 0s 310us/sample - loss: 1.1781 - acc: 0.5833\n",
      "Epoch 83/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2850 - acc: 0.531 - 0s 289us/sample - loss: 1.1647 - acc: 0.6042\n",
      "Epoch 84/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2752 - acc: 0.500 - 0s 269us/sample - loss: 1.1639 - acc: 0.5833\n",
      "Epoch 85/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2167 - acc: 0.593 - 0s 372us/sample - loss: 1.1197 - acc: 0.6458\n",
      "Epoch 86/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2765 - acc: 0.625 - 0s 300us/sample - loss: 1.1694 - acc: 0.6250\n",
      "Epoch 87/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2531 - acc: 0.625 - 0s 310us/sample - loss: 1.1626 - acc: 0.6250\n",
      "Epoch 88/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2302 - acc: 0.531 - 0s 269us/sample - loss: 1.1095 - acc: 0.6250\n",
      "Epoch 89/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2374 - acc: 0.593 - 0s 258us/sample - loss: 1.1316 - acc: 0.6458\n",
      "Epoch 90/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1999 - acc: 0.531 - 0s 258us/sample - loss: 1.0917 - acc: 0.5833\n",
      "Epoch 91/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2217 - acc: 0.562 - 0s 310us/sample - loss: 1.0951 - acc: 0.6250\n",
      "Epoch 92/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1721 - acc: 0.593 - 0s 320us/sample - loss: 1.0689 - acc: 0.6458\n",
      "Epoch 93/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1581 - acc: 0.625 - 0s 320us/sample - loss: 1.0447 - acc: 0.6875\n",
      "Epoch 94/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1384 - acc: 0.656 - 0s 310us/sample - loss: 1.0159 - acc: 0.7292\n",
      "Epoch 95/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2077 - acc: 0.593 - 0s 310us/sample - loss: 1.0849 - acc: 0.6875\n",
      "Epoch 96/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0959 - acc: 0.656 - 0s 331us/sample - loss: 1.0064 - acc: 0.7083\n",
      "Epoch 97/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1168 - acc: 0.625 - 0s 258us/sample - loss: 0.9900 - acc: 0.7083\n",
      "Epoch 98/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1483 - acc: 0.593 - 0s 310us/sample - loss: 1.0417 - acc: 0.6667\n",
      "Epoch 99/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1712 - acc: 0.656 - 0s 289us/sample - loss: 1.0317 - acc: 0.7083\n",
      "Epoch 100/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1080 - acc: 0.656 - 0s 289us/sample - loss: 1.0075 - acc: 0.7292\n",
      "Epoch 101/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1190 - acc: 0.687 - 0s 279us/sample - loss: 1.0110 - acc: 0.7292\n",
      "Epoch 102/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0727 - acc: 0.625 - 0s 279us/sample - loss: 0.9676 - acc: 0.7292\n",
      "Epoch 103/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0881 - acc: 0.687 - 0s 424us/sample - loss: 0.9918 - acc: 0.7083\n",
      "Epoch 104/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0528 - acc: 0.656 - 0s 300us/sample - loss: 0.9198 - acc: 0.7500\n",
      "Epoch 105/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0580 - acc: 0.687 - 0s 331us/sample - loss: 0.9543 - acc: 0.7292\n",
      "Epoch 106/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0263 - acc: 0.718 - 0s 289us/sample - loss: 0.9427 - acc: 0.7500\n",
      "Epoch 107/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0356 - acc: 0.687 - 0s 300us/sample - loss: 0.9286 - acc: 0.7708\n",
      "Epoch 108/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0328 - acc: 0.718 - 0s 227us/sample - loss: 0.9327 - acc: 0.7708\n",
      "Epoch 109/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0110 - acc: 0.750 - 0s 320us/sample - loss: 0.9028 - acc: 0.7917\n",
      "Epoch 110/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0252 - acc: 0.718 - 0s 258us/sample - loss: 0.9327 - acc: 0.7708\n",
      "Epoch 111/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0559 - acc: 0.625 - 0s 279us/sample - loss: 0.9270 - acc: 0.6875\n",
      "Epoch 112/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9695 - acc: 0.750 - 0s 320us/sample - loss: 0.8768 - acc: 0.7917\n",
      "Epoch 113/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9431 - acc: 0.781 - 0s 258us/sample - loss: 0.8761 - acc: 0.8125\n",
      "Epoch 114/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9432 - acc: 0.750 - 0s 300us/sample - loss: 0.8473 - acc: 0.8125\n",
      "Epoch 115/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9475 - acc: 0.750 - 0s 258us/sample - loss: 0.8948 - acc: 0.7708\n",
      "Epoch 116/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9601 - acc: 0.687 - 0s 351us/sample - loss: 0.8582 - acc: 0.7708\n",
      "Epoch 117/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9607 - acc: 0.687 - 0s 310us/sample - loss: 0.8757 - acc: 0.7500\n",
      "Epoch 118/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8918 - acc: 0.812 - 0s 300us/sample - loss: 0.8132 - acc: 0.8542\n",
      "Epoch 119/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9649 - acc: 0.750 - 0s 351us/sample - loss: 0.8609 - acc: 0.8125\n",
      "Epoch 120/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - ETA: 0s - loss: 0.9215 - acc: 0.718 - 0s 351us/sample - loss: 0.8273 - acc: 0.7917\n",
      "Epoch 121/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9119 - acc: 0.781 - 0s 269us/sample - loss: 0.8156 - acc: 0.8333\n",
      "Epoch 122/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8893 - acc: 0.843 - 0s 351us/sample - loss: 0.8013 - acc: 0.8750\n",
      "Epoch 123/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8927 - acc: 0.812 - 0s 362us/sample - loss: 0.7879 - acc: 0.8542\n",
      "Epoch 124/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8419 - acc: 0.875 - 0s 341us/sample - loss: 0.7561 - acc: 0.8958\n",
      "Epoch 125/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8954 - acc: 0.812 - 0s 341us/sample - loss: 0.7881 - acc: 0.8333\n",
      "Epoch 126/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8278 - acc: 0.875 - 0s 300us/sample - loss: 0.7459 - acc: 0.8958\n",
      "Epoch 127/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8756 - acc: 0.781 - 0s 269us/sample - loss: 0.7648 - acc: 0.8333\n",
      "Epoch 128/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8236 - acc: 0.812 - 0s 300us/sample - loss: 0.7408 - acc: 0.8333\n",
      "Epoch 129/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8505 - acc: 0.781 - 0s 300us/sample - loss: 0.7909 - acc: 0.8125\n",
      "Epoch 130/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8423 - acc: 0.812 - 0s 300us/sample - loss: 0.7498 - acc: 0.8542\n",
      "Epoch 131/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7922 - acc: 0.843 - 0s 331us/sample - loss: 0.7350 - acc: 0.8542\n",
      "Epoch 132/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8088 - acc: 0.812 - 0s 269us/sample - loss: 0.7404 - acc: 0.8542\n",
      "Epoch 133/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7485 - acc: 0.906 - 0s 316us/sample - loss: 0.6775 - acc: 0.8958\n",
      "Epoch 134/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8609 - acc: 0.812 - 0s 300us/sample - loss: 0.7682 - acc: 0.8542\n",
      "Epoch 135/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8447 - acc: 0.781 - 0s 258us/sample - loss: 0.7374 - acc: 0.8333\n",
      "Epoch 136/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8050 - acc: 0.843 - 0s 289us/sample - loss: 0.7152 - acc: 0.8750\n",
      "Epoch 137/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7788 - acc: 0.843 - 0s 269us/sample - loss: 0.6836 - acc: 0.8750\n",
      "Epoch 138/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7660 - acc: 0.812 - 0s 403us/sample - loss: 0.6998 - acc: 0.8333\n",
      "Epoch 139/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8015 - acc: 0.843 - 0s 320us/sample - loss: 0.7381 - acc: 0.8542\n",
      "Epoch 140/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7479 - acc: 0.843 - 0s 372us/sample - loss: 0.6589 - acc: 0.8750\n",
      "Epoch 141/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7237 - acc: 0.843 - 0s 300us/sample - loss: 0.6713 - acc: 0.8958\n",
      "Epoch 142/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7706 - acc: 0.843 - 0s 310us/sample - loss: 0.6800 - acc: 0.8750\n",
      "Epoch 143/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7481 - acc: 0.812 - 0s 289us/sample - loss: 0.6444 - acc: 0.8542\n",
      "Epoch 144/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6747 - acc: 0.906 - 0s 285us/sample - loss: 0.6165 - acc: 0.9167\n",
      "Epoch 145/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7590 - acc: 0.812 - 0s 320us/sample - loss: 0.6562 - acc: 0.8542\n",
      "Epoch 146/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7348 - acc: 0.875 - 0s 289us/sample - loss: 0.6405 - acc: 0.8958\n",
      "Epoch 147/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7110 - acc: 0.875 - 0s 279us/sample - loss: 0.6318 - acc: 0.9167\n",
      "Epoch 148/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6788 - acc: 0.875 - 0s 310us/sample - loss: 0.6034 - acc: 0.8958\n",
      "Epoch 149/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6502 - acc: 0.875 - 0s 300us/sample - loss: 0.6016 - acc: 0.8958\n",
      "Epoch 150/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7410 - acc: 0.812 - 0s 434us/sample - loss: 0.6409 - acc: 0.8542\n",
      "Epoch 151/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7048 - acc: 0.812 - 0s 331us/sample - loss: 0.6392 - acc: 0.8542\n",
      "Epoch 152/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6729 - acc: 0.906 - 0s 300us/sample - loss: 0.6070 - acc: 0.9167\n",
      "Epoch 153/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7149 - acc: 0.906 - 0s 310us/sample - loss: 0.6155 - acc: 0.9375\n",
      "Epoch 154/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6209 - acc: 0.906 - 0s 314us/sample - loss: 0.5590 - acc: 0.9375\n",
      "Epoch 155/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7374 - acc: 0.781 - 0s 320us/sample - loss: 0.6475 - acc: 0.8542\n",
      "Epoch 156/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6959 - acc: 0.812 - 0s 362us/sample - loss: 0.6146 - acc: 0.8542\n",
      "Epoch 157/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6432 - acc: 0.875 - 0s 269us/sample - loss: 0.5612 - acc: 0.8958\n",
      "Epoch 158/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6176 - acc: 0.875 - 0s 300us/sample - loss: 0.5359 - acc: 0.9167\n",
      "Epoch 159/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6818 - acc: 0.843 - 0s 269us/sample - loss: 0.5900 - acc: 0.8750\n",
      "Epoch 160/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5875 - acc: 0.906 - 0s 279us/sample - loss: 0.5257 - acc: 0.9375\n",
      "Epoch 161/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6228 - acc: 0.875 - 0s 279us/sample - loss: 0.5741 - acc: 0.8750\n",
      "Epoch 162/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5821 - acc: 0.875 - 0s 327us/sample - loss: 0.5260 - acc: 0.8958\n",
      "Epoch 163/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5834 - acc: 0.906 - 0s 320us/sample - loss: 0.5186 - acc: 0.9167\n",
      "Epoch 164/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6467 - acc: 0.843 - 0s 217us/sample - loss: 0.5713 - acc: 0.8958\n",
      "Epoch 165/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6319 - acc: 0.843 - 0s 289us/sample - loss: 0.5366 - acc: 0.8750\n",
      "Epoch 166/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5850 - acc: 0.843 - 0s 300us/sample - loss: 0.5173 - acc: 0.8958\n",
      "Epoch 167/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6317 - acc: 0.875 - 0s 279us/sample - loss: 0.5624 - acc: 0.9167\n",
      "Epoch 168/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5811 - acc: 0.843 - 0s 269us/sample - loss: 0.5151 - acc: 0.8958\n",
      "Epoch 169/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5135 - acc: 0.906 - 0s 310us/sample - loss: 0.4524 - acc: 0.9375\n",
      "Epoch 170/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5202 - acc: 0.906 - 0s 310us/sample - loss: 0.4837 - acc: 0.9167\n",
      "Epoch 171/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5289 - acc: 0.906 - 0s 279us/sample - loss: 0.4728 - acc: 0.9375\n",
      "Epoch 172/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5051 - acc: 0.906 - 0s 403us/sample - loss: 0.4770 - acc: 0.9167\n",
      "Epoch 173/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5132 - acc: 0.875 - 0s 289us/sample - loss: 0.4579 - acc: 0.9167\n",
      "Epoch 174/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5904 - acc: 0.875 - 0s 269us/sample - loss: 0.5085 - acc: 0.9167\n",
      "Epoch 175/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5446 - acc: 0.843 - 0s 300us/sample - loss: 0.4704 - acc: 0.8958\n",
      "Epoch 176/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5453 - acc: 0.843 - 0s 248us/sample - loss: 0.4731 - acc: 0.8958\n",
      "Epoch 177/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5619 - acc: 0.875 - 0s 382us/sample - loss: 0.4919 - acc: 0.8958\n",
      "Epoch 178/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4972 - acc: 0.906 - 0s 269us/sample - loss: 0.4368 - acc: 0.9375\n",
      "Epoch 179/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - ETA: 0s - loss: 0.5034 - acc: 0.906 - 0s 310us/sample - loss: 0.4342 - acc: 0.9375\n",
      "Epoch 180/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5255 - acc: 0.843 - 0s 331us/sample - loss: 0.4518 - acc: 0.8958\n",
      "Epoch 181/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4808 - acc: 0.875 - 0s 269us/sample - loss: 0.4207 - acc: 0.9167\n",
      "Epoch 182/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4841 - acc: 0.875 - 0s 300us/sample - loss: 0.4254 - acc: 0.9167\n",
      "Epoch 183/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4749 - acc: 0.875 - 0s 279us/sample - loss: 0.4127 - acc: 0.9167\n",
      "Epoch 184/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4773 - acc: 0.906 - 0s 331us/sample - loss: 0.4141 - acc: 0.9375\n",
      "Epoch 185/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5303 - acc: 0.906 - 0s 331us/sample - loss: 0.4648 - acc: 0.9167\n",
      "Epoch 186/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4534 - acc: 0.875 - 0s 320us/sample - loss: 0.3974 - acc: 0.9167\n",
      "Epoch 187/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4522 - acc: 0.906 - 0s 331us/sample - loss: 0.3973 - acc: 0.9375\n",
      "Epoch 188/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5047 - acc: 0.875 - 0s 320us/sample - loss: 0.4302 - acc: 0.9167\n",
      "Epoch 189/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4894 - acc: 0.875 - 0s 331us/sample - loss: 0.4355 - acc: 0.9167\n",
      "Epoch 190/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5454 - acc: 0.843 - 0s 310us/sample - loss: 0.4532 - acc: 0.8750\n",
      "Epoch 191/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4395 - acc: 0.906 - 0s 341us/sample - loss: 0.3950 - acc: 0.9375\n",
      "Epoch 192/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4198 - acc: 0.906 - 0s 320us/sample - loss: 0.3668 - acc: 0.9375\n",
      "Epoch 193/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4824 - acc: 0.843 - 0s 341us/sample - loss: 0.4111 - acc: 0.8750\n",
      "Epoch 194/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4525 - acc: 0.906 - 0s 310us/sample - loss: 0.3802 - acc: 0.9375\n",
      "Epoch 195/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4539 - acc: 0.875 - 0s 341us/sample - loss: 0.3987 - acc: 0.9167\n",
      "Epoch 196/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4631 - acc: 0.875 - 0s 362us/sample - loss: 0.3867 - acc: 0.9167\n",
      "Epoch 197/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3940 - acc: 0.906 - 0s 310us/sample - loss: 0.3521 - acc: 0.9375\n",
      "Epoch 198/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4450 - acc: 0.906 - 0s 341us/sample - loss: 0.3859 - acc: 0.9375\n",
      "Epoch 199/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4062 - acc: 0.906 - 0s 320us/sample - loss: 0.3591 - acc: 0.9375\n",
      "Epoch 200/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3972 - acc: 0.875 - 0s 279us/sample - loss: 0.3579 - acc: 0.8958\n",
      "Epoch 201/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4059 - acc: 0.906 - 0s 300us/sample - loss: 0.3460 - acc: 0.9375\n",
      "Epoch 202/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3507 - acc: 0.906 - 0s 300us/sample - loss: 0.3278 - acc: 0.9375\n",
      "Epoch 203/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3540 - acc: 0.906 - 0s 310us/sample - loss: 0.3127 - acc: 0.9375\n",
      "Epoch 204/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3663 - acc: 0.906 - 0s 351us/sample - loss: 0.3228 - acc: 0.9375\n",
      "Epoch 205/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3863 - acc: 0.875 - 0s 279us/sample - loss: 0.3387 - acc: 0.8958\n",
      "Epoch 206/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4081 - acc: 0.875 - 0s 299us/sample - loss: 0.3549 - acc: 0.9167\n",
      "Epoch 207/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3373 - acc: 0.937 - 0s 300us/sample - loss: 0.2975 - acc: 0.9583\n",
      "Epoch 208/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3556 - acc: 0.937 - 0s 372us/sample - loss: 0.3150 - acc: 0.9583\n",
      "Epoch 209/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3559 - acc: 0.875 - 0s 331us/sample - loss: 0.3107 - acc: 0.9167\n",
      "Epoch 210/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3380 - acc: 0.937 - 0s 310us/sample - loss: 0.3024 - acc: 0.9375\n",
      "Epoch 211/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3856 - acc: 0.937 - 0s 310us/sample - loss: 0.3414 - acc: 0.9375\n",
      "Epoch 212/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3608 - acc: 0.906 - 0s 300us/sample - loss: 0.3156 - acc: 0.9375\n",
      "Epoch 213/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3148 - acc: 0.937 - 0s 289us/sample - loss: 0.2879 - acc: 0.9583\n",
      "Epoch 214/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3213 - acc: 0.906 - 0s 300us/sample - loss: 0.2754 - acc: 0.9375\n",
      "Epoch 215/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3849 - acc: 0.843 - 0s 300us/sample - loss: 0.3384 - acc: 0.8958\n",
      "Epoch 216/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3858 - acc: 0.875 - 0s 248us/sample - loss: 0.3336 - acc: 0.8958\n",
      "Epoch 217/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3427 - acc: 0.875 - 0s 279us/sample - loss: 0.2927 - acc: 0.9167\n",
      "Epoch 218/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3091 - acc: 0.906 - 0s 300us/sample - loss: 0.2921 - acc: 0.9375\n",
      "Epoch 219/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3736 - acc: 0.875 - 0s 310us/sample - loss: 0.3083 - acc: 0.9167\n",
      "Epoch 220/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3165 - acc: 0.937 - 0s 289us/sample - loss: 0.2957 - acc: 0.9375\n",
      "Epoch 221/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3281 - acc: 0.937 - 0s 217us/sample - loss: 0.3211 - acc: 0.9375\n",
      "Epoch 222/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.4325 - acc: 0.875 - 0s 331us/sample - loss: 0.3512 - acc: 0.9167\n",
      "Epoch 223/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3691 - acc: 0.875 - 0s 289us/sample - loss: 0.3260 - acc: 0.8958\n",
      "Epoch 224/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3105 - acc: 0.937 - 0s 300us/sample - loss: 0.2690 - acc: 0.9583\n",
      "Epoch 225/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3731 - acc: 0.906 - 0s 269us/sample - loss: 0.3061 - acc: 0.9375\n",
      "Epoch 226/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3201 - acc: 0.875 - 0s 300us/sample - loss: 0.2784 - acc: 0.9167\n",
      "Epoch 227/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3679 - acc: 0.906 - 0s 269us/sample - loss: 0.3079 - acc: 0.9375\n",
      "Epoch 228/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2942 - acc: 0.906 - 0s 300us/sample - loss: 0.2549 - acc: 0.9375\n",
      "Epoch 229/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3111 - acc: 0.968 - 0s 279us/sample - loss: 0.2635 - acc: 0.9792\n",
      "Epoch 230/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3218 - acc: 0.937 - 0s 320us/sample - loss: 0.2796 - acc: 0.9375\n",
      "Epoch 231/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2580 - acc: 0.937 - 0s 300us/sample - loss: 0.2346 - acc: 0.9375\n",
      "Epoch 232/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2748 - acc: 1.000 - 0s 269us/sample - loss: 0.2462 - acc: 1.0000\n",
      "Epoch 233/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3177 - acc: 0.906 - 0s 279us/sample - loss: 0.2593 - acc: 0.9375\n",
      "Epoch 234/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2534 - acc: 1.000 - 0s 289us/sample - loss: 0.2197 - acc: 1.0000\n",
      "Epoch 235/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3296 - acc: 0.906 - 0s 269us/sample - loss: 0.2713 - acc: 0.9375\n",
      "Epoch 236/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2562 - acc: 1.000 - 0s 300us/sample - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 237/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3063 - acc: 0.937 - 0s 289us/sample - loss: 0.2612 - acc: 0.9583\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - ETA: 0s - loss: 0.2844 - acc: 0.906 - 0s 310us/sample - loss: 0.2499 - acc: 0.9167\n",
      "Epoch 239/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2591 - acc: 0.937 - 0s 279us/sample - loss: 0.2283 - acc: 0.9583\n",
      "Epoch 240/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3247 - acc: 0.875 - 0s 320us/sample - loss: 0.2648 - acc: 0.9167\n",
      "Epoch 241/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.3910 - acc: 0.843 - 0s 320us/sample - loss: 0.3160 - acc: 0.8958\n",
      "Epoch 242/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2448 - acc: 0.968 - 0s 300us/sample - loss: 0.2074 - acc: 0.9792\n",
      "Epoch 243/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2256 - acc: 0.937 - 0s 300us/sample - loss: 0.2048 - acc: 0.9583\n",
      "Epoch 244/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2796 - acc: 0.937 - 0s 320us/sample - loss: 0.2410 - acc: 0.9583\n",
      "Epoch 245/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2726 - acc: 0.968 - 0s 289us/sample - loss: 0.2301 - acc: 0.9792\n",
      "Epoch 246/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2683 - acc: 0.937 - 0s 310us/sample - loss: 0.2350 - acc: 0.9375\n",
      "Epoch 247/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2628 - acc: 0.937 - 0s 320us/sample - loss: 0.2333 - acc: 0.9375\n",
      "Epoch 248/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2929 - acc: 0.906 - 0s 310us/sample - loss: 0.2562 - acc: 0.9167\n",
      "Epoch 249/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2162 - acc: 0.968 - 0s 289us/sample - loss: 0.2310 - acc: 0.9583\n",
      "Epoch 250/250\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2242 - acc: 1.000 - 0s 269us/sample - loss: 0.1949 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Model directory models/dialogue exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to 'C:\\Users\\sreeram\\Desktop\\chatbot\\models\\dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies.keras_policy import KerasPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml', policies=[KerasPolicy(\n",
    "        validation_split=0.0,\n",
    "        epochs=250)])\n",
    "training_data = agent.load_data('stories.md')\n",
    "agent.train(\n",
    "        training_data\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The code block below defines the webhook configuration of the action server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'endpoint' (str) to file 'endpoints.yml'.\n"
     ]
    }
   ],
   "source": [
    "endpoint = \"\"\"\n",
    "action_endpoint:\n",
    "  url: \"http://localhost:5055/webhook\"\n",
    "\"\"\"\n",
    "%store endpoint > endpoints.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:8888/terminals/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b8f271ec50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_core.actions import Action\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"http://localhost:8888/terminals/1\", width=900, height=500)\n",
    "#next run this python -m rasa_core_sdk.endpoint --actions actions C:\\ProgramData\\Anaconda3\\Lib\\site-packages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the path should be the locatoin where you have saved your code (above prompt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "now lets talk to our bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/sreeram/Desktop/chatbot/models/nlu/default/current\\component_3_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "Hey! I am ThingWorx assistant. How can I help\n",
      "show me the machine status of forklift001\n",
      "Forklift001\n",
      "to see the status click here : http://www.iotspace.io/Thingworx/Things/Forklift001/Properties?apikey=e82d0e47-9f2a-42c6-b6e4-a9006cdf9b18\n",
      "thank you\n",
      "It was pleasure serving you\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "import time\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('C:/Users/sreeram/Desktop/chatbot/models/nlu/default/current')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input().lower()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this is to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"machine_name\",\n",
      "    \"confidence\": 0.6929658651351929\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"machine_name\",\n",
      "      \"confidence\": 0.6929658651351929\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.4679192304611206\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.23245006799697876\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.13156992197036743\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"machine_status+machine_name\",\n",
      "      \"confidence\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"machine_status\",\n",
      "      \"confidence\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"forklift001\",\n",
      "  \"model\": \"current\",\n",
      "  \"project\": \"default\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pprint(interpreter.parse(\"forklift001\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
